{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Q2DjyN_TFPM",
        "outputId": "93f1dd2b-a499-4df8-8435-6d662583f9b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXMJIEBTPIjF",
        "outputId": "8b42afd0-8434-4e47-a2d4-a6069f7f725d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['/content/drive/MyDrive/images_001/images/00001166_000.png', '/content/drive/MyDrive/images_001/images/00001158_001.png', '/content/drive/MyDrive/images_001/images/00001170_003.png', '/content/drive/MyDrive/images_001/images/00001155_000.png', '/content/drive/MyDrive/images_001/images/00001170_000.png', '/content/drive/MyDrive/images_001/images/00001164_000.png', '/content/drive/MyDrive/images_001/images/00001167_000.png', '/content/drive/MyDrive/images_001/images/00001156_002.png', '/content/drive/MyDrive/images_001/images/00001168_000.png', '/content/drive/MyDrive/images_001/images/00001157_002.png']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PSNR: 34.9926 dB SSIM: 0.9497: 100%|██████████| 5261/5261 [1:40:10<00:00,  1.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PSNR: 34.9926 dB SSIM: 0.9497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Library imports\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from torchvision.transforms.functional import to_tensor\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "import math\n",
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "## Local imports\n",
        "from model_metrics import ssim\n",
        "\n",
        "def baseline(image_path, lr_scale=256, hr_scale=1024):\n",
        "\n",
        "    # Load an image\n",
        "    hr_image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "    ## Create the LR image transformer by downsampling the HR image and applying bicubic interpolation\n",
        "    lr_scale = transforms.Resize((lr_scale,lr_scale), interpolation=Image.BICUBIC)\n",
        "\n",
        "    ## Create the restored HR image tranformer (simple classical method) by upsampling the LR image and applying bicubic interpolation\n",
        "    hr_scale = transforms.Resize((hr_scale,hr_scale), interpolation=Image.BICUBIC)\n",
        "\n",
        "    ## Create the LR Image from the original HR Image using the LR Image transformer\n",
        "    lr_image = lr_scale(hr_image)\n",
        "\n",
        "    ## Create the restored HR Image from the LR Image using the classical method of restored HR Image transforms\n",
        "    hr_restore_img = hr_scale(lr_image)\n",
        "\n",
        "    return to_tensor(lr_image), to_tensor(hr_restore_img), to_tensor(hr_image)\n",
        "\n",
        "def run_pipeline(val_data_list, batch_size=1):\n",
        "\n",
        "    ## Create a dictionary to store the results\n",
        "    results = {\n",
        "                    \"mse\": 0,\n",
        "                    \"ssims\": 0,\n",
        "                    \"psnr\": 0,\n",
        "                    \"ssim\": 0,\n",
        "                    \"batch_sizes\": 0,\n",
        "                }\n",
        "\n",
        "    ## Create a progress bar\n",
        "    val_bar = tqdm(val_data_list, total=len(val_data_list))\n",
        "\n",
        "    ## Iterate over the images\n",
        "    for image_path in val_bar:\n",
        "\n",
        "        ## Increment the number of images\n",
        "        results[\"batch_sizes\"] += batch_size\n",
        "\n",
        "        ## Get the LR, restored HR and HR images using the naive super resolution method\n",
        "        lr_img, hr_restore, hr_img = baseline(image_path, lr_scale=256, hr_scale=1024)\n",
        "\n",
        "        ## Calculate the MSE for current image\n",
        "        batch_mse = ((hr_restore - hr_img) ** 2).data.mean()\n",
        "\n",
        "        ## Store the MSE for current image\n",
        "        results[\"mse\"] += batch_mse * batch_size\n",
        "\n",
        "        ## Calculate the SSIM for current image\n",
        "        batch_ssim = ssim(hr_restore.unsqueeze(0), hr_img).item()\n",
        "\n",
        "        ## Store the SSIM for current image\n",
        "        results[\"ssims\"] += batch_ssim * batch_size\n",
        "\n",
        "        ## Calculate the PSNR for current image\n",
        "        results[\"psnr\"] = 10 * math.log10((hr_img.max() ** 2)/ (results[\"mse\"] / results[\"batch_sizes\"]))\n",
        "\n",
        "        ## Calculate the SSIM for all processed images\n",
        "        results[\"ssim\"] = (results[\"ssims\"] / results[\"batch_sizes\"])\n",
        "\n",
        "        ## Update the progress bar\n",
        "        val_bar.set_description(desc=\"PSNR: %.4f dB SSIM: %.4f\"% (results[\"psnr\"], results[\"ssim\"]))\n",
        "\n",
        "    return results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    ## Load the validation data list\n",
        "    all_images_list = glob.glob(f\"/content/drive/MyDrive/images_001/images/*.png\", recursive=True)\n",
        "\n",
        "    print(all_images_list[:10])\n",
        "\n",
        "    ## Run the pipeline\n",
        "    results = run_pipeline(all_images_list, batch_size=1)\n",
        "\n",
        "    ## Print the results\n",
        "    print(\"PSNR: %.4f dB SSIM: %.4f\"% (results[\"psnr\"], results[\"ssim\"]))\n",
        "\n",
        "    ## Save the results\n",
        "    data_frame = pd.DataFrame(data=results, index=range(1, 2))\n",
        "    data_frame.to_csv(\"non_dl_approach_metrics.csv\", index_label=\"Iteration\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aiy5y4y1e4JE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}